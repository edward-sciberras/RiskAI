{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install gym\n",
    "# !pip install keras\n",
    "# !pip install keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Dict, Discrete, Box\n",
    "from enum import Enum\n",
    "from collections import defaultdict\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerrEnums(Enum):\n",
    "    # north america\n",
    "    alaska = 0\n",
    "    alberta = 1\n",
    "    northWestTerritory = 2\n",
    "    ontario = 3\n",
    "    quebec = 4\n",
    "    greenland = 5\n",
    "    westernUnitedStates = 6\n",
    "    easternUnitedStates = 7\n",
    "    centralAmerica = 8\n",
    "    \n",
    "    # south america\n",
    "    venezuela = 9\n",
    "    brazil = 10\n",
    "    peru = 11\n",
    "    argentina = 12\n",
    "    \n",
    "    # europe\n",
    "    iceland = 13\n",
    "    greatBritain = 14\n",
    "    westernEurope = 15\n",
    "    northernEurope = 16\n",
    "    southernEurope = 17\n",
    "    scandinavia = 18\n",
    "    ukraine = 19\n",
    "    \n",
    "    # africa\n",
    "    northAfrica = 20\n",
    "    egypt = 21\n",
    "    eastAfrica = 22\n",
    "    congo = 23\n",
    "    southAfrica = 24\n",
    "    madagascar = 25\n",
    "    \n",
    "    # asia\n",
    "    middleEast = 26\n",
    "    afghanistan = 27\n",
    "    ural = 28\n",
    "    india = 29\n",
    "    china = 30\n",
    "    siberia = 31\n",
    "    siam = 32\n",
    "    mongolia = 33\n",
    "    irkutsk = 34\n",
    "    yakutsk = 35\n",
    "    kamchatka = 36\n",
    "    japan = 37\n",
    "    \n",
    "    # australia\n",
    "    indonesia = 38\n",
    "    newGuinea = 39\n",
    "    westernAustralia = 40\n",
    "    easternAustralia = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContEnums(Enum):\n",
    "    northAmerica = 0\n",
    "    southAmerica = 1\n",
    "    europe = 2\n",
    "    africa = 3\n",
    "    asia = 4\n",
    "    australia = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TroopEnums(Enum):\n",
    "    infantry = 0\n",
    "    cavalry = 1\n",
    "    artillery = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiseTerritories(): \n",
    "    terrList = []\n",
    "    \n",
    "    # north american territories\n",
    "    terrList.append(Territory(TerrEnums.alaska, \"Alaska\", None, ContEnums.northAmerica, 0, [TerrEnums.alberta, TerrEnums.northWestTerritory, TerrEnums.kamchatka]))\n",
    "    terrList.append(Territory(TerrEnums.alberta, \"Alberta\", None, ContEnums.northAmerica, 0, [TerrEnums.alaska, TerrEnums.northWestTerritory, TerrEnums.ontario, TerrEnums.westernUnitedStates]))\n",
    "    terrList.append(Territory(TerrEnums.northWestTerritory, \"North West Territory\", None, ContEnums.northAmerica, 0, [TerrEnums.alaska, TerrEnums.alberta, TerrEnums.ontario, TerrEnums.greenland]))\n",
    "    terrList.append(Territory(TerrEnums.ontario, \"Ontario\", None, ContEnums.northAmerica, 0, [TerrEnums.northWestTerritory, TerrEnums.quebec, TerrEnums.alberta, TerrEnums.westernUnitedStates, TerrEnums.easternUnitedStates, TerrEnums.greenland]))\n",
    "    terrList.append(Territory(TerrEnums.quebec, \"Quebec\", None, ContEnums.northAmerica, 0, [TerrEnums.ontario, TerrEnums.easternUnitedStates, TerrEnums.greenland]))\n",
    "    terrList.append(Territory(TerrEnums.greenland, \"Greenland\", None, ContEnums.northAmerica, 0, [TerrEnums.northWestTerritory, TerrEnums.ontario, TerrEnums.quebec, TerrEnums.iceland]))\n",
    "    terrList.append(Territory(TerrEnums.westernUnitedStates, \"Western United States\", None, ContEnums.northAmerica, 0, [TerrEnums.alberta, TerrEnums.ontario, TerrEnums.easternUnitedStates, TerrEnums.centralAmerica]))\n",
    "    terrList.append(Territory(TerrEnums.easternUnitedStates, \"Eastern United States\", None, ContEnums.northAmerica, 0, [TerrEnums.westernUnitedStates, TerrEnums.ontario, TerrEnums.quebec, TerrEnums.centralAmerica]))\n",
    "    terrList.append(Territory(TerrEnums.centralAmerica, \"Central America\", None, ContEnums.northAmerica, 0, [TerrEnums.westernUnitedStates, TerrEnums.easternUnitedStates, TerrEnums.venezuela]))\n",
    "    \n",
    "    # south american territories\n",
    "    terrList.append(Territory(TerrEnums.venezuela, \"Venezuela\", None, ContEnums.southAmerica, 0, [TerrEnums.centralAmerica, TerrEnums.brazil, TerrEnums.peru]))\n",
    "    terrList.append(Territory(TerrEnums.brazil, \"Brazil\", None, ContEnums.southAmerica, 0, [TerrEnums.venezuela, TerrEnums.peru, TerrEnums.argentina, TerrEnums.northAfrica]))\n",
    "    terrList.append(Territory(TerrEnums.peru, \"Peru\", None, ContEnums.southAmerica, 0, [TerrEnums.brazil, TerrEnums.venezuela, TerrEnums.argentina]))\n",
    "    terrList.append(Territory(TerrEnums.argentina, \"Argentina\", None, ContEnums.southAmerica, 0, [TerrEnums.peru, TerrEnums.brazil]))\n",
    "    \n",
    "    # european territories\n",
    "    terrList.append(Territory(TerrEnums.iceland, \"Iceland\", None, ContEnums.europe, 0, [TerrEnums.greenland, TerrEnums.greatBritain, TerrEnums.scandinavia]))\n",
    "    terrList.append(Territory(TerrEnums.greatBritain, \"Great Britain\", None, ContEnums.europe, 0, [TerrEnums.iceland, TerrEnums.scandinavia, TerrEnums.westernEurope, TerrEnums.northernEurope]))\n",
    "    terrList.append(Territory(TerrEnums.westernEurope, \"Western Europe\", None, ContEnums.europe, 0, [TerrEnums.northAfrica, TerrEnums.greatBritain, TerrEnums.southernEurope, TerrEnums.northernEurope]))\n",
    "    terrList.append(Territory(TerrEnums.northernEurope, \"Northern Europe\", None, ContEnums.europe, 0, [TerrEnums.greatBritain, TerrEnums.scandinavia, TerrEnums.ukraine, TerrEnums.southernEurope, TerrEnums.westernEurope]))\n",
    "    terrList.append(Territory(TerrEnums.southernEurope, \"Southern Europe\", None, ContEnums.europe, 0, [TerrEnums.northAfrica, TerrEnums.egypt, TerrEnums.middleEast, TerrEnums.westernEurope, TerrEnums.northernEurope, TerrEnums.ukraine]))\n",
    "    terrList.append(Territory(TerrEnums.scandinavia, \"Scandinavia\", None, ContEnums.europe, 0, [TerrEnums.ukraine, TerrEnums.iceland, TerrEnums.greatBritain, TerrEnums.northernEurope]))\n",
    "    terrList.append(Territory(TerrEnums.ukraine, \"Ukraine\", None, ContEnums.europe, 0, [TerrEnums.southernEurope, TerrEnums.northernEurope, TerrEnums.scandinavia, TerrEnums.ural, TerrEnums.afghanistan, TerrEnums.middleEast]))\n",
    "         \n",
    "    # african territories\n",
    "    terrList.append(Territory(TerrEnums.northAfrica, \"North Africa\", None, ContEnums.africa, 0, [TerrEnums.brazil, TerrEnums.westernEurope, TerrEnums.southernEurope, TerrEnums.egypt, TerrEnums.eastAfrica, TerrEnums.congo]))\n",
    "    terrList.append(Territory(TerrEnums.egypt, \"Egypt\", None, ContEnums.africa, 0, [TerrEnums.northAfrica, TerrEnums.southernEurope, TerrEnums.eastAfrica, TerrEnums.middleEast]))\n",
    "    terrList.append(Territory(TerrEnums.eastAfrica, \"East Africa\", None, ContEnums.africa, 0, [TerrEnums.middleEast, TerrEnums.egypt, TerrEnums.congo, TerrEnums.southAfrica, TerrEnums.madagascar]))\n",
    "    terrList.append(Territory(TerrEnums.congo, \"Congo\", None, ContEnums.africa, 0, [TerrEnums.northAfrica, TerrEnums.eastAfrica, TerrEnums.southAfrica]))\n",
    "    terrList.append(Territory(TerrEnums.southAfrica, \"South Africa\", None, ContEnums.africa, 0, [TerrEnums.madagascar, TerrEnums.congo, TerrEnums.eastAfrica]))\n",
    "    terrList.append(Territory(TerrEnums.madagascar, \"Madagascar\", None, ContEnums.africa, 0, [TerrEnums.southAfrica, TerrEnums.eastAfrica]))\n",
    "    \n",
    "    # asian territories\n",
    "    terrList.append(Territory(TerrEnums.middleEast, \"Middle East\", None, ContEnums.asia, 0, [TerrEnums.egypt, TerrEnums.southernEurope, TerrEnums.eastAfrica, TerrEnums.afghanistan, TerrEnums.india]))\n",
    "    terrList.append(Territory(TerrEnums.afghanistan, \"Afghanistan\", None, ContEnums.asia, 0, [TerrEnums.ukraine, TerrEnums.middleEast, TerrEnums.india, TerrEnums.china, TerrEnums.ural]))\n",
    "    terrList.append(Territory(TerrEnums.ural, \"Ural\", None, ContEnums.asia, 0, [TerrEnums.ukraine, TerrEnums.afghanistan, TerrEnums.china, TerrEnums.siberia]))\n",
    "    terrList.append(Territory(TerrEnums.india, \"India\", None, ContEnums.asia, 0, [TerrEnums.middleEast, TerrEnums.afghanistan, TerrEnums.china, TerrEnums.siam]))\n",
    "    terrList.append(Territory(TerrEnums.china, \"China\", None, ContEnums.asia, 0, [TerrEnums.siam, TerrEnums.india, TerrEnums.afghanistan, TerrEnums.ural, TerrEnums.siberia, TerrEnums.mongolia]))\n",
    "    terrList.append(Territory(TerrEnums.siberia, \"Siberia\", None, ContEnums.asia, 0, [TerrEnums.ural, TerrEnums.yakutsk, TerrEnums.irkutsk, TerrEnums.mongolia, TerrEnums.china]))\n",
    "    terrList.append(Territory(TerrEnums.siam, \"Siam\", None, ContEnums.asia, 0, [TerrEnums.india, TerrEnums.china, TerrEnums.indonesia]))\n",
    "    terrList.append(Territory(TerrEnums.mongolia, \"Mongolia\", None, ContEnums.asia, 0, [TerrEnums.china, TerrEnums.siberia, TerrEnums.irkutsk, TerrEnums.kamchatka, TerrEnums.japan]))\n",
    "    terrList.append(Territory(TerrEnums.irkutsk, \"Irkutsk\", None, ContEnums.asia, 0, [TerrEnums.mongolia, TerrEnums.siberia, TerrEnums.yakutsk, TerrEnums.kamchatka]))\n",
    "    terrList.append(Territory(TerrEnums.yakutsk, \"Yakutsk\", None, ContEnums.asia, 0, [TerrEnums.siberia, TerrEnums.irkutsk, TerrEnums.kamchatka]))\n",
    "    terrList.append(Territory(TerrEnums.kamchatka, \"Kamchatka\", None, ContEnums.asia, 0, [TerrEnums.alaska, TerrEnums.japan, TerrEnums.yakutsk, TerrEnums.irkutsk, TerrEnums.mongolia]))\n",
    "    terrList.append(Territory(TerrEnums.japan, \"Japan\", None, ContEnums.asia, 0, [TerrEnums.mongolia, TerrEnums.kamchatka]))\n",
    "    \n",
    "    # australian territories\n",
    "    terrList.append(Territory(TerrEnums.indonesia, \"Indonesia\", None, ContEnums.australia, 0, [TerrEnums.siam, TerrEnums.newGuinea, TerrEnums.westernAustralia]))\n",
    "    terrList.append(Territory(TerrEnums.newGuinea, \"New Guinea\", None, ContEnums.australia, 0, [TerrEnums.indonesia, TerrEnums.westernAustralia, TerrEnums.easternAustralia]))\n",
    "    terrList.append(Territory(TerrEnums.westernAustralia, \"Western Australia\", None, ContEnums.australia, 0, [TerrEnums.indonesia, TerrEnums.newGuinea, TerrEnums.easternAustralia]))\n",
    "    terrList.append(Territory(TerrEnums.easternAustralia, \"Eastern Australia\", None, ContEnums.australia, 0, [TerrEnums.newGuinea, TerrEnums.westernAustralia]))\n",
    "\n",
    "    return terrList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialisePlayers():\n",
    "    player0 = Player(0, 0, [], [])\n",
    "    player1 = SimpleAgent(1, 0, [], [], random.randint(0, 2))\n",
    "    player2 = SimpleAgent(2, 0, [], [], random.randint(0, 2))\n",
    "    player3 = SimpleAgent(3, 0, [], [], random.randint(0, 2))\n",
    "    \n",
    "    playerList = [player0, player1, player2, player3]\n",
    "    \n",
    "    return playerList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiseCards():\n",
    "    cardList = []\n",
    "    troopTypeCounter = 0\n",
    "    territories = list(range(0, len(TerrEnums)))\n",
    "    random.shuffle(territories)\n",
    "    while territories:\n",
    "        # random territory each time\n",
    "        randomTerrIndex = territories.pop()\n",
    "        if troopTypeCounter <= 13: # for infantry\n",
    "            cardList.append(Card(TroopEnums.infantry.value, TerrEnums(randomTerrIndex).value))\n",
    "        elif troopTypeCounter <= 27: # for cavelry\n",
    "            cardList.append(Card(TroopEnums.cavalry.value, TerrEnums(randomTerrIndex).value))\n",
    "        elif troopTypeCounter <= 41: # for artillery\n",
    "            cardList.append(Card(TroopEnums.artillery.value, TerrEnums(randomTerrIndex).value))\n",
    "            \n",
    "        troopTypeCounter += 1\n",
    "            \n",
    "    return cardList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiseContinents(terrList): \n",
    "    contList = []\n",
    "    for continent in ContEnums:\n",
    "        tempList = []\n",
    "        for territory in terrList:\n",
    "            # if terr continent value is equal to current continent in loop then add\n",
    "            if territory.parentContinent.value == continent.value:\n",
    "                tempList.append(territory)\n",
    "        \n",
    "        if continent.value == 0:\n",
    "            contList.append(Continent(continent, \"North America\", tempList, 5, len(tempList)))\n",
    "        elif continent.value == 1:\n",
    "            contList.append(Continent(continent, \"South America\", tempList, 2, len(tempList)))\n",
    "        elif continent.value == 2:\n",
    "            contList.append(Continent(continent, \"Europe\", tempList, 5, len(tempList)))\n",
    "        elif continent.value == 3:\n",
    "            contList.append(Continent(continent, \"Africa\", tempList, 3, len(tempList)))\n",
    "        elif continent.value == 4:\n",
    "            contList.append(Continent(continent, \"Asia\", tempList, 7, len(tempList)))\n",
    "        elif continent.value == 5:\n",
    "            contList.append(Continent(continent, \"Australia\", tempList, 2, len(tempList)))\n",
    "        \n",
    "    return contList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Territory:\n",
    "    def __init__(self, index, name, ownedBy, parentContinent, currTroops, connections):\n",
    "        self.index = index\n",
    "        self.name = name\n",
    "        self.ownedBy = ownedBy\n",
    "        self.parentContinent = parentContinent\n",
    "        self.currTroops = currTroops\n",
    "        self.connections = connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Continent:\n",
    "    def __init__(self, index, name, territories, troopsWhenFull, noOfCountries):\n",
    "        self.index = index\n",
    "        self.name = name\n",
    "        self.territories = territories\n",
    "        self.troopsWhenFull = troopsWhenFull\n",
    "        self.noOfCountries = noOfCountries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Card:\n",
    "    def __init__(self, troop, territory):\n",
    "        self.troop = troop\n",
    "        self.territory = territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, index, troopTotal, territories, cards):\n",
    "        self.index = index\n",
    "        self.troopTotal = troopTotal\n",
    "        self.territories = territories\n",
    "        self.cards = cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAgent:\n",
    "    def __init__(self, index, troopTotal, territories, cards, strategy):\n",
    "        self.index = index\n",
    "        self.troopTotal = troopTotal\n",
    "        self.territories = territories\n",
    "        self.cards = cards\n",
    "        self.strategy = strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Board:\n",
    "    def __init__(self):\n",
    "        self.players = initialisePlayers()\n",
    "        self.noOfPlayers = len(self.players)\n",
    "        self.terrList = initialiseTerritories()\n",
    "        self.continents = initialiseContinents(self.terrList)\n",
    "        self.cards = initialiseCards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns list of random numbers between 1 to 6\n",
    "def rollDice(noOfDice):\n",
    "    numList = []\n",
    "    for i in range(noOfDice):\n",
    "        numList.append(random.randint(1, 6))\n",
    "        \n",
    "    return numList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if card submitted is owned by player\n",
    "def checkCardTerritory(card, player):\n",
    "    cardTerr = card.territory\n",
    "    terrList = player.territories\n",
    "\n",
    "    terrIndexList = []\n",
    "    for terr in terrList:\n",
    "        terrIndexList.append(terr.index.value)\n",
    "    \n",
    "    # if the card had a territory that is owned by the player than add 2 more troops\n",
    "    if cardTerr in terrIndexList:\n",
    "        return 2 \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trades in cards when possible\n",
    "def tradingCards(player, board):\n",
    "    cards = player.cards\n",
    "    tradedTroops = 0\n",
    "    \n",
    "    # checking if possible to trade in anything as 3 cards minimum\n",
    "    if len(player.cards) > 2:\n",
    "        cardTypeList = []\n",
    "        for card in player.cards:\n",
    "            cardTypeList.append(card.troop)\n",
    "\n",
    "        # checking for one of team type since highest value\n",
    "        if cardTypeList.count(0) >= 1 and cardTypeList.count(1) >= 1 and cardTypeList.count(2) >= 1:\n",
    "            infantryCardIndex = cardTypeList.index(0)\n",
    "            cardTypeList.pop(infantryCardIndex)\n",
    "            poppedCard = cards.pop(infantryCardIndex)\n",
    "            tradedTroops += checkCardTerritory(poppedCard, player)\n",
    "\n",
    "            cavalryCardIndex = cardTypeList.index(1)\n",
    "            cardTypeList.pop(cavalryCardIndex)\n",
    "            poppedCard = cards.pop(cavalryCardIndex)\n",
    "            tradedTroops += checkCardTerritory(poppedCard, player)\n",
    "\n",
    "            artilleryCardIndex = cardTypeList.index(2)\n",
    "            cardTypeList.pop(artilleryCardIndex)\n",
    "            poppedCard = cards.pop(artilleryCardIndex)\n",
    "            tradedTroops += checkCardTerritory(poppedCard, player)\n",
    "\n",
    "            tradedTroops += 10\n",
    "            return tradedTroops\n",
    "\n",
    "        # checking for 3 artilleries\n",
    "        if cardTypeList.count(2) >= 3:\n",
    "            artilleryCardIndex = cardTypeList.index(2)\n",
    "            cardTypeList.pop(artilleryCardIndex)\n",
    "            poppedCard = cards.pop(artilleryCardIndex)\n",
    "            tradedTroops += checkCardTerritory(poppedCard, player)\n",
    "\n",
    "            artilleryCardIndex = cardTypeList.index(2)\n",
    "            cardTypeList.pop(artilleryCardIndex)\n",
    "            poppedCard = cards.pop(artilleryCardIndex)\n",
    "            tradedTroops += checkCardTerritory(poppedCard, player)\n",
    "\n",
    "            artilleryCardIndex = cardTypeList.index(2)\n",
    "            cardTypeList.pop(artilleryCardIndex)\n",
    "            poppedCard = cards.pop(artilleryCardIndex)\n",
    "            tradedTroops += checkCardTerritory(poppedCard, player)\n",
    "\n",
    "            tradedTroops += 8\n",
    "            return tradedTroops\n",
    "\n",
    "        # checking for 3 calvary\n",
    "        if cardTypeList.count(1) >= 3:\n",
    "            cavalryCardIndex = cardTypeList.index(1)\n",
    "            cardTypeList.pop(cavalryCardIndex)\n",
    "            poppedCard = cards.pop(cavalryCardIndex)\n",
    "            tradedTroops += checkCardTerritory(poppedCard, player)\n",
    "\n",
    "            cavalryCardIndex = cardTypeList.index(1)\n",
    "            cardTypeList.pop(cavalryCardIndex)\n",
    "            poppedCard = cards.pop(cavalryCardIndex)\n",
    "            tradedTroops += checkCardTerritory(poppedCard, player)\n",
    "\n",
    "            cavalryCardIndex = cardTypeList.index(1)\n",
    "            cardTypeList.pop(cavalryCardIndex)\n",
    "            poppedCard = cards.pop(cavalryCardIndex)\n",
    "            tradedTroops += checkCardTerritory(poppedCard, player)\n",
    "\n",
    "            tradedTroops += 6\n",
    "            return tradedTroops\n",
    "\n",
    "        # checking for 3 infantry\n",
    "        if cardTypeList.count(0) >= 3:\n",
    "            infantryCardIndex = cardTypeList.index(0)\n",
    "            cardTypeList.pop(infantryCardIndex)\n",
    "            poppedCard = cards.pop(infantryCardIndex)\n",
    "            tradedTroops += checkCardTerritory(poppedCard, player)\n",
    "\n",
    "            infantryCardIndex = cardTypeList.index(0)\n",
    "            cardTypeList.pop(infantryCardIndex)\n",
    "            poppedCard = cards.pop(infantryCardIndex)\n",
    "            tradedTroops += checkCardTerritory(poppedCard, player)\n",
    "\n",
    "            infantryCardIndex = cardTypeList.index(0)\n",
    "            cardTypeList.pop(infantryCardIndex)\n",
    "            poppedCard = cards.pop(infantryCardIndex)\n",
    "            tradedTroops += checkCardTerritory(poppedCard, player)\n",
    "\n",
    "            tradedTroops += 4\n",
    "            return tradedTroops\n",
    "\n",
    "    return tradedTroops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def receiveAndPlaceTroops(player, board, strat):\n",
    "    noOfTerrs = len(player.territories)\n",
    "    if noOfTerrs <= 0:\n",
    "        return\n",
    "    \n",
    "    # using int to ignore decimal\n",
    "    troopsRecieved = int(noOfTerrs / 3)\n",
    "    \n",
    "    # can not recieve less than 3 troops in a turn\n",
    "    if troopsRecieved < 3:\n",
    "        troopsRecieved = 3\n",
    "    \n",
    "    # checking if player owns a whole continent to recieve bonus troops\n",
    "    for continent in board.continents:\n",
    "        continentSet = set(continent.territories)\n",
    "        playerTerrSet = set(player.territories)\n",
    "        if continentSet.issubset(playerTerrSet):\n",
    "            troopsRecieved += continent.troopsWhenFull\n",
    "    \n",
    "    # automatically trading in cards when possible\n",
    "    troopsRecieved += tradingCards(player, board)\n",
    "        \n",
    "    player.troopTotal += troopsRecieved\n",
    "    \n",
    "    if strat == 0: # passive strat\n",
    "        # always places recieved troops in terr with least troops\n",
    "        troopCountList = []\n",
    "        for terr in player.territories:\n",
    "            troopCountList.append(terr.currTroops)\n",
    "        leastTroopTerr = min(troopCountList)\n",
    "        leastTroopIndex = troopCountList.index(leastTroopTerr)\n",
    "        \n",
    "        player.territories[leastTroopIndex].currTroops += troopsRecieved\n",
    "    elif strat == 1: # pacifist strat\n",
    "        # divides troops recieved equally between terrs\n",
    "        playerTerrList = list(range(0, len(player.territories) - 1))\n",
    "        random.shuffle(playerTerrList)\n",
    "        \n",
    "        i = 0\n",
    "        while troopsRecieved != 0:\n",
    "            if len(playerTerrList) == 0:\n",
    "                return\n",
    "            currTerr = playerTerrList[i % len(playerTerrList)]\n",
    "            player.territories[currTerr].currTroops += 1\n",
    "            \n",
    "            troopsRecieved -= 1\n",
    "            i += 1\n",
    "    elif strat == 2: # aggressive strat\n",
    "        # places troops in terr with most troops\n",
    "        troopCountList = []\n",
    "        for terr in player.territories:\n",
    "            troopCountList.append(terr.currTroops)\n",
    "        mostTroopTerr = max(troopCountList)\n",
    "        mostTroopIndex = troopCountList.index(mostTroopTerr)\n",
    "        \n",
    "        player.territories[mostTroopIndex].currTroops += troopsRecieved\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attacking(player, board, strat):\n",
    "    # used to check if player took over a territory or not\n",
    "    startingTerrCount = len(player.territories)\n",
    "    if startingTerrCount <= 0:\n",
    "        return\n",
    "    \n",
    "    if strat == 0: # passive strat\n",
    "        # does not attack\n",
    "        return\n",
    "    elif strat == 1: # pacifist strat\n",
    "        # only attacks 1 to 3 times\n",
    "        attackingRounds = random.randint(1, 3)\n",
    "    elif strat == 2: # aggressive strat\n",
    "        # attacks 7 to 9 times\n",
    "        attackingRounds = random.randint(7, 9)\n",
    "\n",
    "    for i in range(attackingRounds):\n",
    "        # getting list of indexes of possible territories to attack\n",
    "        playerTerrList = player.territories\n",
    "        possibleAttacks = []\n",
    "        troopCount = []\n",
    "        \n",
    "        for terr in playerTerrList:\n",
    "            # player can not attack with just 1 troop\n",
    "            if terr.currTroops < 2:\n",
    "                continue\n",
    "            for connection in terr.connections:\n",
    "                isOwnTerr = False\n",
    "                # checking if owner of territory has less than 10 left\n",
    "                currTerr = board.terrList[connection.value]\n",
    "                defendingPlayerTerrs = len(board.players[currTerr.ownedBy].territories)\n",
    "                \n",
    "                # smaller nations should be targetted\n",
    "                if defendingPlayerTerrs >= 10:\n",
    "                    smallPlayer = False\n",
    "                else:\n",
    "                    smallPlayer = True\n",
    "                    \n",
    "                for terr2 in playerTerrList:\n",
    "                    if terr2.index == connection:\n",
    "                        isOwnTerr = True\n",
    "                \n",
    "                # making sure that you can't attack your own terr\n",
    "                if isOwnTerr == False:\n",
    "                    # using a tuple to show which territory to attack from\n",
    "                    possibleAttacks.append((terr.index.value, connection.value, smallPlayer))\n",
    "                    # mirror array with how many troops there are for each territory above\n",
    "                    troopCount.append((terr.currTroops, board.terrList[connection.value].currTroops, smallPlayer))\n",
    "                    \n",
    "        if len(possibleAttacks) == 0:\n",
    "            return\n",
    "        \n",
    "        smallPlayerAttacks = []\n",
    "        for possAttack in troopCount:\n",
    "            if possAttack[2] == True:\n",
    "                smallPlayerAttacks.append(possAttack)\n",
    "        \n",
    "        # if there is an attack on a small nation then attack that\n",
    "        if len(smallPlayerAttacks) > 0:\n",
    "            # currently will just choose to attack the territory that has the biggest discrepiancy\n",
    "            \n",
    "            smallPlayerAttacks = list(set(smallPlayerAttacks))\n",
    "            troopDifference = []\n",
    "            for possAttack in smallPlayerAttacks:\n",
    "                troopDifference.append(possAttack[0] - possAttack[1])\n",
    "\n",
    "            maxTroopDifference = max(troopDifference)\n",
    "            chosenBattleIndex = troopDifference.index(maxTroopDifference)\n",
    "            randomBattle = random.randint(0, len(possibleAttacks) - 1)\n",
    "            chosenBattle = possibleAttacks[randomBattle]\n",
    "\n",
    "            blitzBattle(chosenBattle, board, player)\n",
    "        else:\n",
    "            # choose to attack the territory that has the biggest discrepiancy\n",
    "            troopDifference = []\n",
    "            for possAttack in troopCount:\n",
    "                troopDifference.append(possAttack[0] - possAttack[1])\n",
    "\n",
    "            maxTroopDifference = max(troopDifference)\n",
    "            chosenBattleIndex = troopDifference.index(maxTroopDifference)\n",
    "            randomBattle = random.randint(0, len(possibleAttacks) - 1)\n",
    "            chosenBattle = possibleAttacks[chosenBattleIndex]\n",
    "\n",
    "            blitzBattle(chosenBattle, board, player)\n",
    "        \n",
    "    # if attacking player wins 1 terr in round then recieve card\n",
    "    endingTerrCount = len(player.territories)\n",
    "    if endingTerrCount > startingTerrCount and len(board.cards) != 0:\n",
    "        randomCardIndex = random.randint(0, len(board.cards) - 1)\n",
    "        player.cards.append(board.cards.pop(randomCardIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blitz battle will continue going until there is a winner\n",
    "def blitzBattle(battle, board, player):\n",
    "    attackingTerr = board.terrList[battle[0]]\n",
    "    defendingTerr = board.terrList[battle[1]]\n",
    "    defendingPlayer = board.players[defendingTerr.ownedBy]\n",
    "    \n",
    "    totalAttackingTroops = attackingTerr.currTroops\n",
    "    totalDefendingTroops = defendingTerr.currTroops\n",
    "    \n",
    "    # since its blitz it will keep going till 1 side loses\n",
    "    attackingWins = None\n",
    "    while not (totalAttackingTroops < 1 or totalDefendingTroops == 0):\n",
    "        # always defending and attacking with max amount of troops\n",
    "        if totalAttackingTroops >= 3:\n",
    "            attackingTroops = 3\n",
    "        elif totalAttackingTroops == 2:\n",
    "            attackingTroops = 2\n",
    "\n",
    "        if totalDefendingTroops >= 2:\n",
    "            defendingTroops = 2\n",
    "        else:\n",
    "            defendingTroops = 1\n",
    "        \n",
    "        attackingRolls = rollDice(attackingTroops)\n",
    "        defendingRolls = rollDice(defendingTroops)\n",
    "        \n",
    "        attackingRolls.sort(reverse = True)\n",
    "        defendingRolls.sort(reverse = True)\n",
    "        \n",
    "        attackingTroopsLost = 0\n",
    "        defendingTroopsLost = 0\n",
    "        if len(defendingRolls) == 2:\n",
    "            if attackingRolls[0] > defendingRolls[0]:\n",
    "                defendingTroopsLost += 1\n",
    "            else:\n",
    "                attackingTroopsLost += 1\n",
    "            \n",
    "            if attackingRolls[1] > defendingRolls[1]:\n",
    "                defendingTroopsLost += 1\n",
    "            else:\n",
    "                attackingTroopsLost += 1\n",
    "        elif len(defendingRolls) == 1:\n",
    "            if attackingRolls[0] > defendingRolls[0]:\n",
    "                defendingTroopsLost += 1\n",
    "            else:\n",
    "                attackingTroopsLost += 1\n",
    "                \n",
    "        totalAttackingTroops -= attackingTroopsLost\n",
    "        totalDefendingTroops -= defendingTroopsLost\n",
    "        \n",
    "    if totalAttackingTroops > 1:\n",
    "        attackingWins = True\n",
    "    else:\n",
    "        attackingWins = False\n",
    "\n",
    "    if attackingWins == False:\n",
    "        # entering here means that the defender won\n",
    "        None\n",
    "    else:\n",
    "        # entering here means that the attacker won\n",
    "        defendingTerr.ownedBy = player.index\n",
    "        defendingTerr.currTroops = 1\n",
    "        attackingTerr.currTroops -= 1\n",
    "        defendingPlayer.territories.remove(defendingTerr)\n",
    "        player.territories.append(defendingTerr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if there is a route between terrs that the player wants to move troops between\n",
    "def isReachable(player, a, b):\n",
    "    edgeDict = defaultdict(list)\n",
    "    for terr in player.territories:\n",
    "        for connection in terr.connections:\n",
    "            edgeDict[terr.index.value].append(connection.value)\n",
    "    \n",
    "    noOfTerrs = len(edgeDict)\n",
    "    visited = [False] * (42)\n",
    "    queue = []\n",
    "    \n",
    "    queue.append(a.index.value)\n",
    "    visited[a.index.value] = True\n",
    "    \n",
    "    while queue:\n",
    "        n = queue.pop(0)\n",
    "        if n == b.index.value:\n",
    "            return True\n",
    "        \n",
    "        for i in edgeDict[n]:\n",
    "            if visited[i] == False:\n",
    "                queue.append(i)\n",
    "                visited[i] = True\n",
    "                \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fortifying(player, board, strat):\n",
    "    if strat == 0: # passive strat\n",
    "        # getting terr with most and least troops\n",
    "        troopCount = []\n",
    "        for terr in player.territories:\n",
    "            troopCount.append(terr.currTroops)\n",
    "            \n",
    "        if len(troopCount) == 0 or len(troopCount) == 1 or len(troopCount) == 2:\n",
    "            return\n",
    "            \n",
    "        maxTroops = max(troopCount)\n",
    "        minTroops = min(troopCount)\n",
    "        totalTroops = maxTroops + minTroops\n",
    "\n",
    "        maxTroopsIndex = troopCount.index(maxTroops)\n",
    "        minTroopIndex = troopCount.index(minTroops)\n",
    "\n",
    "        maxTroopTerr = player.territories[maxTroopsIndex]\n",
    "        minTroopTerr = player.territories[minTroopIndex]\n",
    "        \n",
    "        # checking if there is valid path\n",
    "        if isReachable(player, maxTroopTerr, minTroopTerr) == True:\n",
    "            # splitting troops between terrs with most and least troops\n",
    "            if totalTroops % 2 == 0:\n",
    "                maxTroopTerr.currTroops = totalTroops / 2\n",
    "                minTroopTerr.currTroops = totalTroops / 2\n",
    "            else:\n",
    "                maxTroopTerr.currTroops = int(totalTroops / 2) + 1\n",
    "                minTroopTerr.currTroops = int(totalTroops / 2)\n",
    "    elif strat == 1: # pacifist strat\n",
    "        return\n",
    "    elif strat == 2: # aggressive strat\n",
    "        # getting terr with most and least troops\n",
    "        troopCount = []\n",
    "        for terr in player.territories:\n",
    "            troopCount.append(terr.currTroops)\n",
    "            \n",
    "        if len(troopCount) == 0 or len(troopCount) == 1 or len(troopCount) == 2:\n",
    "            return\n",
    "            \n",
    "        maxTroops = max(troopCount)\n",
    "        sortedTroops = troopCount.copy()\n",
    "        sortedTroops.sort()\n",
    "        max2Troops = sortedTroops[-2] # getting 2nd highest value in list\n",
    "        \n",
    "        totalTroops = maxTroops + max2Troops\n",
    "\n",
    "        maxTroopsIndex = troopCount.index(maxTroops)\n",
    "        max2TroopsIndex = troopCount.index(max2Troops)\n",
    "\n",
    "        maxTroopTerr = player.territories[maxTroopsIndex]\n",
    "        max2TroopTerr = player.territories[max2TroopsIndex]\n",
    "        \n",
    "        # checking if there is valid path\n",
    "        if isReachable(player, maxTroopTerr, max2TroopTerr) == True:\n",
    "            # moves troops from terr with most troops and 2nd most\n",
    "            if totalTroops % 2 == 0:\n",
    "                maxTroopTerr.currTroops = totalTroops / 2\n",
    "                max2TroopTerr.currTroops = totalTroops / 2\n",
    "            else:\n",
    "                maxTroopTerr.currTroops = int(totalTroops / 2) + 1\n",
    "                max2TroopTerr.currTroops = int(totalTroops / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openAI gym environment is extended\n",
    "class RiskEnv(Env):\n",
    "    # init the game when called\n",
    "    def __init__(self):\n",
    "        # shows different strategies that can be used\n",
    "        self.action_space = Discrete(3)\n",
    "        # will hold percentage of board owned\n",
    "        self.observation_space = Box(low = np.array([0]), high = np.array([100]))\n",
    "        \n",
    "        # initialise board\n",
    "        STARTING_TROOPS = 30\n",
    "\n",
    "        self.board = Board()\n",
    "    \n",
    "        startingRolls = []\n",
    "        # making sure that all values are different to avoid confusion with starting order\n",
    "        while len(list(set(startingRolls))) != self.board.noOfPlayers:\n",
    "            startingRolls = rollDice(self.board.noOfPlayers)\n",
    "\n",
    "        # sorting rolls with their values and getting the turn order\n",
    "        sortedRolls = sorted(((value, index) for index, value in enumerate(startingRolls)), reverse = True)\n",
    "        self.turnOrder = []\n",
    "        for i in range(len(sortedRolls)):\n",
    "            self.turnOrder.append(sortedRolls[i][1])\n",
    "\n",
    "        # spreading territories between players\n",
    "        tempTerrList = self.board.terrList.copy()\n",
    "        i = 0\n",
    "        while len(tempTerrList) != 0:\n",
    "            self.currPlayerTurn = self.turnOrder[i % self.board.noOfPlayers] # getting the current player turn from rolls\n",
    "            randomTerrIndex = random.randint(0, len(tempTerrList) - 1) # getting a random territory index\n",
    "            currTerr = tempTerrList.pop(randomTerrIndex) # getting actual territory\n",
    "            self.board.players[self.currPlayerTurn].territories.append(currTerr) # adding territory to players\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        for player in self.board.players:\n",
    "            # putting at least 1 troop on every territory\n",
    "            for terr in player.territories:\n",
    "                terr.ownedBy = player.index\n",
    "                terr.currTroops = 1\n",
    "                player.troopTotal += 1\n",
    "\n",
    "            # randomizing the places of the leftover troops\n",
    "            leftoverTroops = STARTING_TROOPS - player.troopTotal\n",
    "            for i in range(leftoverTroops):\n",
    "                randomTerrIndex = random.randint(0, len(player.territories) - 1)\n",
    "                player.territories[randomTerrIndex].currTroops += 1\n",
    "                player.troopTotal += 1\n",
    "\n",
    "        self.turns = 0\n",
    "        self.turnOrderIndex = 0\n",
    "        self.reward = 0\n",
    "        self.state = (len(self.board.players[0].territories) / 42) * 100\n",
    "    \n",
    "    # represents a turn in the game\n",
    "    def step(self, action):\n",
    "        TOTAL_TERRS = 42\n",
    "        \n",
    "        # decide which strat to play\n",
    "        recievingStrat = action\n",
    "        attackingStrat = action\n",
    "        fortifyingStrat = action\n",
    "\n",
    "        currPlayerTurn = self.turnOrder[self.turnOrderIndex % self.board.noOfPlayers] # constantly changing player according to value of starting dice\n",
    "\n",
    "        if currPlayerTurn == 0:\n",
    "            receiveAndPlaceTroops(self.board.players[0], self.board, recievingStrat)\n",
    "            attacking(self.board.players[0], self.board, attackingStrat)\n",
    "            fortifying(self.board.players[0], self.board, fortifyingStrat)\n",
    "\n",
    "            if len(self.board.players[0].territories) == 42:\n",
    "                gameOver = True\n",
    "\n",
    "        elif currPlayerTurn == 1:\n",
    "            receiveAndPlaceTroops(self.board.players[1], self.board, self.board.players[1].strategy)\n",
    "            attacking(self.board.players[1], self.board, self.board.players[1].strategy)\n",
    "            fortifying(self.board.players[1], self.board, self.board.players[1].strategy)\n",
    "\n",
    "            if len(self.board.players[1].territories) == 42:\n",
    "                gameOver = True\n",
    "\n",
    "        elif currPlayerTurn == 2:\n",
    "            receiveAndPlaceTroops(self.board.players[2], self.board, self.board.players[2].strategy)\n",
    "            attacking(self.board.players[2], self.board, self.board.players[2].strategy)\n",
    "            fortifying(self.board.players[2], self.board, self.board.players[2].strategy)\n",
    "\n",
    "            if len(self.board.players[2].territories) == 42:\n",
    "                gameOver = True\n",
    "        else:\n",
    "            receiveAndPlaceTroops(self.board.players[3], self.board, self.board.players[3].strategy)\n",
    "            attacking(self.board.players[3], self.board, self.board.players[3].strategy)\n",
    "            fortifying(self.board.players[3], self.board, self.board.players[3].strategy)\n",
    "\n",
    "            if len(self.board.players[3].territories) == 42:\n",
    "                gameOver = True\n",
    "                \n",
    "        boardOwnedAfter = len(self.board.players[0].territories)\n",
    "            \n",
    "        self.turnOrderIndex += 1\n",
    "        self.turns += 1\n",
    "        \n",
    "        self.reward = 0\n",
    "        # calculate reward\n",
    "        if boardOwnedAfter == TOTAL_TERRS: # if player wins\n",
    "            self.reward += 500\n",
    "            done = True\n",
    "        elif len(self.board.players[1].territories) == TOTAL_TERRS or len(self.board.players[2].territories) == TOTAL_TERRS or len(self.board.players[3].territories) == TOTAL_TERRS: # if player loses\n",
    "            self.reward += -50\n",
    "            done = True\n",
    "        elif boardOwnedAfter == 0: # if player is knocked out\n",
    "            self.reward += -75\n",
    "            done = True\n",
    "        elif self.turns == 200:\n",
    "            # if game lasts more than 200 turns take into account how many territories player had\n",
    "            playerTerrs = len(self.board.players[0].territories)\n",
    "            agent1Terrs = len(self.board.players[1].territories)\n",
    "            agent2Terrs = len(self.board.players[2].territories)\n",
    "            agent3Terrs = len(self.board.players[3].territories)\n",
    "            \n",
    "            terrsList = [playerTerrs, agent1Terrs, agent2Terrs, agent3Terrs]\n",
    "            terrsList.sort()\n",
    "            \n",
    "            if playerTerrs == terrsList[3]:\n",
    "                self.reward += 250\n",
    "            elif playerTerrs == terrsList[2]:\n",
    "                self.reward += 100\n",
    "            elif playerTerrs == terrsList[1]:\n",
    "                self.reward += 0\n",
    "            elif playerTerrs == terrsList[0]:\n",
    "                self.reward += -50\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        # every full turn deduct one point to discourage taking long\n",
    "        self.reward -= 1\n",
    "\n",
    "        # Set placeholder for info, needed for openAI\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, self.reward, done, info\n",
    "    \n",
    "    # used by openAI gym when rendering is involved\n",
    "    def render(self):\n",
    "        # not used since there is no GUI\n",
    "        pass\n",
    "    \n",
    "    # restarting the environment for a new game\n",
    "    def reset(self):\n",
    "        STARTING_TROOPS = 30\n",
    "        self.board = Board()\n",
    "    \n",
    "        startingRolls = []\n",
    "        # making sure that all values are different to avoid confusion with starting order\n",
    "        while len(list(set(startingRolls))) != self.board.noOfPlayers:\n",
    "            startingRolls = rollDice(self.board.noOfPlayers)\n",
    "\n",
    "        # sorting rolls with their values and getting the turn order\n",
    "        sortedRolls = sorted(((value, index) for index, value in enumerate(startingRolls)), reverse = True)\n",
    "        self.turnOrder = []\n",
    "        for i in range(len(sortedRolls)):\n",
    "            self.turnOrder.append(sortedRolls[i][1])\n",
    "\n",
    "        # spreading territories between players\n",
    "        tempTerrList = self.board.terrList.copy()\n",
    "        i = 0\n",
    "        while len(tempTerrList) != 0:\n",
    "            self.currPlayerTurn = self.turnOrder[i % self.board.noOfPlayers] # getting the current player turn from rolls\n",
    "            randomTerrIndex = random.randint(0, len(tempTerrList) - 1) # getting a random territory index\n",
    "            currTerr = tempTerrList.pop(randomTerrIndex) # getting actual territory\n",
    "            self.board.players[self.currPlayerTurn].territories.append(currTerr) # adding territory to players\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        for player in self.board.players:\n",
    "            # putting at least 1 troop on every territory\n",
    "            for terr in player.territories:\n",
    "                terr.ownedBy = player.index\n",
    "                terr.currTroops = 1\n",
    "                player.troopTotal += 1\n",
    "\n",
    "            # randomizing the places of the leftover troops\n",
    "            leftoverTroops = STARTING_TROOPS - player.troopTotal\n",
    "            for i in range(leftoverTroops):\n",
    "                randomTerrIndex = random.randint(0, len(player.territories) - 1)\n",
    "                player.territories[randomTerrIndex].currTroops += 1\n",
    "                player.troopTotal += 1\n",
    "        \n",
    "        self.turns = 0\n",
    "        self.turnOrderIndex = 0\n",
    "        self.state = (len(self.board.players[0].territories) / 42) * 100\n",
    "        self.reward = 0\n",
    "        \n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RiskEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode: 0\n",
      "Score: 50\n",
      "\n",
      "Episode: 1\n",
      "Score: 50\n",
      "\n",
      "Episode: 2\n",
      "Score: 50\n",
      "\n",
      "Episode: 3\n",
      "Score: 50\n",
      "\n",
      "Episode: 4\n",
      "Score: -100\n",
      "\n",
      "Episode: 5\n",
      "Score: 50\n",
      "\n",
      "Episode: 6\n",
      "Score: 50\n",
      "\n",
      "Episode: 7\n",
      "Score: -100\n",
      "\n",
      "Episode: 8\n",
      "Score: 50\n",
      "\n",
      "Episode: 9\n",
      "Score: 50\n",
      "\n",
      "Episode: 10\n",
      "Score: 50\n",
      "\n",
      "Episode: 11\n",
      "Score: -100\n",
      "\n",
      "Episode: 12\n",
      "Score: -200\n",
      "\n",
      "Episode: 13\n",
      "Score: 50\n",
      "\n",
      "Episode: 14\n",
      "Score: 50\n",
      "\n",
      "Episode: 15\n",
      "Score: 50\n",
      "\n",
      "Episode: 16\n",
      "Score: 50\n",
      "\n",
      "Episode: 17\n",
      "Score: -100\n",
      "\n",
      "Episode: 18\n",
      "Score: 50\n",
      "\n",
      "Episode: 19\n",
      "Score: 50\n",
      "\n",
      "Episode: 20\n",
      "Score: 50\n",
      "\n",
      "Episode: 21\n",
      "Score: 50\n",
      "\n",
      "Episode: 22\n",
      "Score: 50\n",
      "\n",
      "Episode: 23\n",
      "Score: 50\n",
      "\n",
      "Episode: 24\n",
      "Score: -100\n",
      "\n",
      "Episode: 25\n",
      "Score: 50\n",
      "\n",
      "Episode: 26\n",
      "Score: 50\n",
      "\n",
      "Episode: 27\n",
      "Score: 50\n",
      "\n",
      "Episode: 28\n",
      "Score: 50\n",
      "\n",
      "Episode: 29\n",
      "Score: 50\n",
      "\n",
      "Episode: 30\n",
      "Score: 50\n",
      "\n",
      "Episode: 31\n",
      "Score: 50\n",
      "\n",
      "Episode: 32\n",
      "Score: 50\n",
      "\n",
      "Episode: 33\n",
      "Score: 50\n",
      "\n",
      "Episode: 34\n",
      "Score: 50\n",
      "\n",
      "Episode: 35\n",
      "Score: 50\n",
      "\n",
      "Episode: 36\n",
      "Score: -100\n",
      "\n",
      "Episode: 37\n",
      "Score: 50\n",
      "\n",
      "Episode: 38\n",
      "Score: 50\n",
      "\n",
      "Episode: 39\n",
      "Score: 50\n",
      "\n",
      "Episode: 40\n",
      "Score: 50\n",
      "\n",
      "Episode: 41\n",
      "Score: 50\n",
      "\n",
      "Episode: 42\n",
      "Score: 50\n",
      "\n",
      "Episode: 43\n",
      "Score: 50\n",
      "\n",
      "Episode: 44\n",
      "Score: 50\n",
      "\n",
      "Episode: 45\n",
      "Score: 50\n",
      "\n",
      "Episode: 46\n",
      "Score: 50\n",
      "\n",
      "Episode: 47\n",
      "Score: 50\n",
      "\n",
      "Episode: 48\n",
      "Score: 50\n",
      "\n",
      "Episode: 49\n",
      "Score: 50\n",
      "\n",
      "Episode: 50\n",
      "Score: 50\n",
      "\n",
      "Episode: 51\n",
      "Score: 50\n",
      "\n",
      "Episode: 52\n",
      "Score: 50\n",
      "\n",
      "Episode: 53\n",
      "Score: 50\n",
      "\n",
      "Episode: 54\n",
      "Score: -250\n",
      "\n",
      "Episode: 55\n",
      "Score: 50\n",
      "\n",
      "Episode: 56\n",
      "Score: -100\n",
      "\n",
      "Episode: 57\n",
      "Score: -100\n",
      "\n",
      "Episode: 58\n",
      "Score: 50\n",
      "\n",
      "Episode: 59\n",
      "Score: -100\n",
      "\n",
      "Episode: 60\n",
      "Score: 50\n",
      "\n",
      "Episode: 61\n",
      "Score: 50\n",
      "\n",
      "Episode: 62\n",
      "Score: 50\n",
      "\n",
      "Episode: 63\n",
      "Score: 50\n",
      "\n",
      "Episode: 64\n",
      "Score: -100\n",
      "\n",
      "Episode: 65\n",
      "Score: 50\n",
      "\n",
      "Episode: 66\n",
      "Score: 50\n",
      "\n",
      "Episode: 67\n",
      "Score: 50\n",
      "\n",
      "Episode: 68\n",
      "Score: 50\n",
      "\n",
      "Episode: 69\n",
      "Score: -250\n",
      "\n",
      "Episode: 70\n",
      "Score: 50\n",
      "\n",
      "Episode: 71\n",
      "Score: -200\n",
      "\n",
      "Episode: 72\n",
      "Score: 50\n",
      "\n",
      "Episode: 73\n",
      "Score: 50\n",
      "\n",
      "Episode: 74\n",
      "Score: 50\n",
      "\n",
      "Episode: 75\n",
      "Score: 50\n",
      "\n",
      "Episode: 76\n",
      "Score: 50\n",
      "\n",
      "Episode: 77\n",
      "Score: 50\n",
      "\n",
      "Episode: 78\n",
      "Score: 50\n",
      "\n",
      "Episode: 79\n",
      "Score: -100\n",
      "\n",
      "Episode: 80\n",
      "Score: 50\n",
      "\n",
      "Episode: 81\n",
      "Score: 50\n",
      "\n",
      "Episode: 82\n",
      "Score: 50\n",
      "\n",
      "Episode: 83\n",
      "Score: 50\n",
      "\n",
      "Episode: 84\n",
      "Score: 50\n",
      "\n",
      "Episode: 85\n",
      "Score: 50\n",
      "\n",
      "Episode: 86\n",
      "Score: 50\n",
      "\n",
      "Episode: 87\n",
      "Score: 50\n",
      "\n",
      "Episode: 88\n",
      "Score: -100\n",
      "\n",
      "Episode: 89\n",
      "Score: 50\n",
      "\n",
      "Episode: 90\n",
      "Score: 50\n",
      "\n",
      "Episode: 91\n",
      "Score: 50\n",
      "\n",
      "Episode: 92\n",
      "Score: 50\n",
      "\n",
      "Episode: 93\n",
      "Score: 50\n",
      "\n",
      "Episode: 94\n",
      "Score: 50\n",
      "\n",
      "Episode: 95\n",
      "Score: 50\n",
      "\n",
      "Episode: 96\n",
      "Score: 50\n",
      "\n",
      "Episode: 97\n",
      "Score: 50\n",
      "\n",
      "Episode: 98\n",
      "Score: 50\n",
      "\n",
      "Episode: 99\n",
      "Score: -200\n",
      "\n",
      "\n",
      "Average Score: -2.0\n"
     ]
    }
   ],
   "source": [
    "# testing the game with random actions and getting average score\n",
    "episodes = 100\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    totalScore = 0\n",
    "    \n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    \n",
    "    totalScore += score\n",
    "    print(\"\\nEpisode:\", episode)\n",
    "    print(\"Score:\", score)\n",
    "    \n",
    "print(\"\\n\\nAverage Score:\", totalScore / episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = env.observation_space.shape # getting shape of observation space\n",
    "actions = env.action_space.n # getting number of actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    # building model with 3 dense layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, activation = 'relu', input_shape = states))\n",
    "    model.add(Dense(24, activation = 'relu'))\n",
    "    model.add(Dense(actions, activation = 'linear'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 24)                48        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 24)                600       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 75        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 723\n",
      "Trainable params: 723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy() # soft-maxing Q learning\n",
    "    memory = SequentialMemory(limit = 500000, window_length = 1)\n",
    "    dqn = DQNAgent(model = model, memory = memory, policy = policy, nb_actions = actions, nb_steps_warmup = 1000, target_model_update = 1e-2)\n",
    "    \n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edwar\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 500000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "  252/10000 [..............................] - ETA: 5s - reward: -0.0079"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edwar\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 32s 3ms/step - reward: 0.0000e+00\n",
      "50 episodes - episode_reward: 0.000 [-250.000, 50.000] - loss: 94.520 - mae: 6.302 - mean_q: 9.190\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 36s 4ms/step - reward: 0.0200\n",
      "50 episodes - episode_reward: 4.000 [-250.000, 50.000] - loss: 99.066 - mae: 9.082 - mean_q: 13.148\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 36s 4ms/step - reward: 0.1350\n",
      "50 episodes - episode_reward: 27.000 [-200.000, 50.000] - loss: 111.047 - mae: 11.269 - mean_q: 16.339\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 35s 4ms/step - reward: 0.0600\n",
      "50 episodes - episode_reward: 12.000 [-250.000, 50.000] - loss: 109.259 - mae: 12.124 - mean_q: 17.590\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 36s 4ms/step - reward: 0.0625\n",
      "50 episodes - episode_reward: 15.880 [-200.000, 50.000] - loss: 107.734 - mae: 13.222 - mean_q: 19.282\n",
      "\n",
      "Interval 6 (50000 steps performed)\n",
      "10000/10000 [==============================] - 36s 4ms/step - reward: 0.1900\n",
      "50 episodes - episode_reward: 38.000 [-100.000, 50.000] - loss: 112.080 - mae: 14.251 - mean_q: 20.728\n",
      "\n",
      "Interval 7 (60000 steps performed)\n",
      "10000/10000 [==============================] - 37s 4ms/step - reward: 0.0750\n",
      "50 episodes - episode_reward: 15.000 [-200.000, 50.000] - loss: 110.372 - mae: 14.163 - mean_q: 20.601\n",
      "\n",
      "Interval 8 (70000 steps performed)\n",
      "10000/10000 [==============================] - 37s 4ms/step - reward: 0.1500\n",
      "50 episodes - episode_reward: 30.560 [-200.000, 328.000] - loss: 104.486 - mae: 13.028 - mean_q: 18.947\n",
      "\n",
      "Interval 9 (80000 steps performed)\n",
      "10000/10000 [==============================] - 38s 4ms/step - reward: 0.0250\n",
      "50 episodes - episode_reward: 5.000 [-200.000, 50.000] - loss: 116.191 - mae: 12.419 - mean_q: 17.950\n",
      "\n",
      "Interval 10 (90000 steps performed)\n",
      "10000/10000 [==============================] - 40s 4ms/step - reward: 0.1200\n",
      "50 episodes - episode_reward: 24.000 [-200.000, 50.000] - loss: 110.028 - mae: 13.513 - mean_q: 19.615\n",
      "\n",
      "Interval 11 (100000 steps performed)\n",
      "10000/10000 [==============================] - 41s 4ms/step - reward: 0.0550\n",
      "50 episodes - episode_reward: 11.000 [-200.000, 50.000] - loss: 108.688 - mae: 12.379 - mean_q: 17.879\n",
      "\n",
      "Interval 12 (110000 steps performed)\n",
      "10000/10000 [==============================] - 42s 4ms/step - reward: 0.1050\n",
      "50 episodes - episode_reward: 21.000 [-250.000, 50.000] - loss: 113.125 - mae: 12.178 - mean_q: 17.546\n",
      "\n",
      "Interval 13 (120000 steps performed)\n",
      "10000/10000 [==============================] - 44s 4ms/step - reward: 0.0850\n",
      "50 episodes - episode_reward: 17.000 [-250.000, 50.000] - loss: 107.216 - mae: 11.286 - mean_q: 16.219\n",
      "\n",
      "Interval 14 (130000 steps performed)\n",
      "10000/10000 [==============================] - 44s 4ms/step - reward: 0.0850\n",
      "50 episodes - episode_reward: 17.000 [-200.000, 50.000] - loss: 111.626 - mae: 10.499 - mean_q: 15.000\n",
      "\n",
      "Interval 15 (140000 steps performed)\n",
      "10000/10000 [==============================] - 44s 4ms/step - reward: 0.0650\n",
      "50 episodes - episode_reward: 13.000 [-250.000, 50.000] - loss: 114.152 - mae: 11.027 - mean_q: 15.816\n",
      "\n",
      "Interval 16 (150000 steps performed)\n",
      "10000/10000 [==============================] - 45s 5ms/step - reward: 0.0500\n",
      "50 episodes - episode_reward: 10.000 [-250.000, 50.000] - loss: 117.496 - mae: 11.897 - mean_q: 17.042\n",
      "\n",
      "Interval 17 (160000 steps performed)\n",
      "10000/10000 [==============================] - 47s 5ms/step - reward: 0.1250\n",
      "50 episodes - episode_reward: 25.000 [-200.000, 300.000] - loss: 113.465 - mae: 12.506 - mean_q: 17.979\n",
      "\n",
      "Interval 18 (170000 steps performed)\n",
      "10000/10000 [==============================] - 47s 5ms/step - reward: 0.1150\n",
      "50 episodes - episode_reward: 23.000 [-200.000, 50.000] - loss: 119.361 - mae: 12.856 - mean_q: 18.530\n",
      "\n",
      "Interval 19 (180000 steps performed)\n",
      "10000/10000 [==============================] - 47s 5ms/step - reward: 0.0250\n",
      "50 episodes - episode_reward: 5.000 [-200.000, 50.000] - loss: 105.170 - mae: 12.130 - mean_q: 17.512\n",
      "\n",
      "Interval 20 (190000 steps performed)\n",
      "10000/10000 [==============================] - 48s 5ms/step - reward: 0.1250\n",
      "50 episodes - episode_reward: 25.000 [-200.000, 50.000] - loss: 116.086 - mae: 11.433 - mean_q: 16.384\n",
      "\n",
      "Interval 21 (200000 steps performed)\n",
      "10000/10000 [==============================] - 49s 5ms/step - reward: 0.0400\n",
      "50 episodes - episode_reward: 8.000 [-250.000, 50.000] - loss: 111.189 - mae: 12.082 - mean_q: 17.421\n",
      "\n",
      "Interval 22 (210000 steps performed)\n",
      "10000/10000 [==============================] - 50s 5ms/step - reward: -0.0450\n",
      "50 episodes - episode_reward: -9.000 [-250.000, 50.000] - loss: 114.896 - mae: 13.302 - mean_q: 19.183\n",
      "\n",
      "Interval 23 (220000 steps performed)\n",
      "10000/10000 [==============================] - 52s 5ms/step - reward: 0.1250\n",
      "51 episodes - episode_reward: 20.745 [-200.000, 308.000] - loss: 111.420 - mae: 12.891 - mean_q: 18.620\n",
      "\n",
      "Interval 24 (230000 steps performed)\n",
      "10000/10000 [==============================] - 53s 5ms/step - reward: 0.0850\n",
      "50 episodes - episode_reward: 17.000 [-250.000, 50.000] - loss: 114.614 - mae: 12.327 - mean_q: 17.676\n",
      "\n",
      "Interval 25 (240000 steps performed)\n",
      "10000/10000 [==============================] - 55s 5ms/step - reward: 0.1100\n",
      "50 episodes - episode_reward: 23.040 [-250.000, 352.000] - loss: 110.961 - mae: 10.684 - mean_q: 15.256\n",
      "\n",
      "Interval 26 (250000 steps performed)\n",
      "10000/10000 [==============================] - 56s 6ms/step - reward: 0.1050\n",
      "50 episodes - episode_reward: 21.000 [-250.000, 50.000] - loss: 116.154 - mae: 10.784 - mean_q: 15.402\n",
      "\n",
      "Interval 27 (260000 steps performed)\n",
      "10000/10000 [==============================] - 58s 6ms/step - reward: 0.0150\n",
      "50 episodes - episode_reward: 3.000 [-250.000, 50.000] - loss: 108.461 - mae: 10.969 - mean_q: 15.721\n",
      "\n",
      "Interval 28 (270000 steps performed)\n",
      "10000/10000 [==============================] - 57s 6ms/step - reward: 0.0950\n",
      "50 episodes - episode_reward: 19.000 [-250.000, 50.000] - loss: 115.700 - mae: 11.353 - mean_q: 16.250\n",
      "\n",
      "Interval 29 (280000 steps performed)\n",
      "10000/10000 [==============================] - 58s 6ms/step - reward: 0.0900: 0s - reward:\n",
      "50 episodes - episode_reward: 18.000 [-250.000, 50.000] - loss: 110.631 - mae: 10.142 - mean_q: 14.435\n",
      "\n",
      "Interval 30 (290000 steps performed)\n",
      "10000/10000 [==============================] - 59s 6ms/step - reward: 0.0450\n",
      "50 episodes - episode_reward: 9.000 [-250.000, 50.000] - loss: 113.617 - mae: 10.619 - mean_q: 15.191\n",
      "\n",
      "Interval 31 (300000 steps performed)\n",
      "10000/10000 [==============================] - 60s 6ms/step - reward: 0.1500\n",
      "50 episodes - episode_reward: 30.000 [-200.000, 50.000] - loss: 117.343 - mae: 10.761 - mean_q: 15.307\n",
      "\n",
      "Interval 32 (310000 steps performed)\n",
      "10000/10000 [==============================] - 61s 6ms/step - reward: 0.0250\n",
      "50 episodes - episode_reward: 5.000 [-250.000, 50.000] - loss: 118.695 - mae: 11.926 - mean_q: 17.047\n",
      "\n",
      "Interval 33 (320000 steps performed)\n",
      "10000/10000 [==============================] - 63s 6ms/step - reward: 0.0450\n",
      "50 episodes - episode_reward: 9.000 [-200.000, 50.000] - loss: 114.437 - mae: 11.167 - mean_q: 15.964\n",
      "\n",
      "Interval 34 (330000 steps performed)\n",
      "10000/10000 [==============================] - 62s 6ms/step - reward: 0.1200\n",
      "50 episodes - episode_reward: 24.000 [-200.000, 50.000] - loss: 110.586 - mae: 10.036 - mean_q: 14.313\n",
      "\n",
      "Interval 35 (340000 steps performed)\n",
      "10000/10000 [==============================] - 62s 6ms/step - reward: 0.2150\n",
      "50 episodes - episode_reward: 43.420 [-100.000, 321.000] - loss: 115.192 - mae: 10.483 - mean_q: 14.920\n",
      "\n",
      "Interval 36 (350000 steps performed)\n",
      "10000/10000 [==============================] - 68s 7ms/step - reward: 0.0700\n",
      "50 episodes - episode_reward: 14.000 [-250.000, 50.000] - loss: 114.031 - mae: 10.452 - mean_q: 14.901\n",
      "\n",
      "Interval 37 (360000 steps performed)\n",
      "10000/10000 [==============================] - 69s 7ms/step - reward: 0.1250\n",
      "50 episodes - episode_reward: 25.000 [-250.000, 50.000] - loss: 114.977 - mae: 11.021 - mean_q: 15.724\n",
      "\n",
      "Interval 38 (370000 steps performed)\n",
      "10000/10000 [==============================] - 67s 7ms/step - reward: 0.0450\n",
      "50 episodes - episode_reward: 9.000 [-200.000, 50.000] - loss: 114.328 - mae: 10.077 - mean_q: 14.326\n",
      "\n",
      "Interval 39 (380000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 68s 7ms/step - reward: 0.0700\n",
      "50 episodes - episode_reward: 14.000 [-200.000, 50.000] - loss: 116.563 - mae: 10.699 - mean_q: 15.242\n",
      "\n",
      "Interval 40 (390000 steps performed)\n",
      "10000/10000 [==============================] - 69s 7ms/step - reward: 0.0750\n",
      "50 episodes - episode_reward: 15.000 [-250.000, 50.000] - loss: 116.141 - mae: 11.083 - mean_q: 15.820\n",
      "\n",
      "Interval 41 (400000 steps performed)\n",
      "10000/10000 [==============================] - 70s 7ms/step - reward: 0.0800\n",
      "50 episodes - episode_reward: 16.000 [-200.000, 50.000] - loss: 114.515 - mae: 12.356 - mean_q: 17.735\n",
      "\n",
      "Interval 42 (410000 steps performed)\n",
      "10000/10000 [==============================] - 72s 7ms/step - reward: 0.0500\n",
      "50 episodes - episode_reward: 10.000 [-250.000, 50.000] - loss: 114.852 - mae: 11.401 - mean_q: 16.309\n",
      "\n",
      "Interval 43 (420000 steps performed)\n",
      "10000/10000 [==============================] - 73s 7ms/step - reward: 0.1750\n",
      "50 episodes - episode_reward: 35.000 [-100.000, 50.000] - loss: 113.697 - mae: 10.458 - mean_q: 14.882\n",
      "\n",
      "Interval 44 (430000 steps performed)\n",
      "10000/10000 [==============================] - 74s 7ms/step - reward: 0.0800\n",
      "50 episodes - episode_reward: 16.000 [-200.000, 50.000] - loss: 114.535 - mae: 11.088 - mean_q: 15.856\n",
      "\n",
      "Interval 45 (440000 steps performed)\n",
      "10000/10000 [==============================] - 75s 8ms/step - reward: 0.0950\n",
      "50 episodes - episode_reward: 19.000 [-200.000, 50.000] - loss: 113.869 - mae: 11.213 - mean_q: 16.037\n",
      "\n",
      "Interval 46 (450000 steps performed)\n",
      "10000/10000 [==============================] - 76s 8ms/step - reward: -0.0150\n",
      "50 episodes - episode_reward: -3.000 [-250.000, 50.000] - loss: 112.443 - mae: 10.833 - mean_q: 15.464\n",
      "\n",
      "Interval 47 (460000 steps performed)\n",
      "10000/10000 [==============================] - 77s 8ms/step - reward: 0.0800\n",
      "50 episodes - episode_reward: 16.000 [-250.000, 50.000] - loss: 115.159 - mae: 10.048 - mean_q: 14.270\n",
      "\n",
      "Interval 48 (470000 steps performed)\n",
      "10000/10000 [==============================] - 79s 8ms/step - reward: 0.0200\n",
      "50 episodes - episode_reward: 4.000 [-250.000, 50.000] - loss: 119.059 - mae: 11.178 - mean_q: 15.930\n",
      "\n",
      "Interval 49 (480000 steps performed)\n",
      "10000/10000 [==============================] - 81s 8ms/step - reward: 0.1700\n",
      "50 episodes - episode_reward: 34.460 [-200.000, 323.000] - loss: 114.921 - mae: 11.266 - mean_q: 16.095\n",
      "\n",
      "Interval 50 (490000 steps performed)\n",
      "10000/10000 [==============================] - 81s 8ms/step - reward: 0.1050\n",
      "done, took 2766.646 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21f34c988e0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn = build_agent(model, actions) # deep q learning regression method\n",
    "dqn.compile(Adam(lr = 1e-3), metrics = ['mae']) # using mean absolute error\n",
    "dqn.fit(env, nb_steps = 500000, visualize = False, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 100 episodes ...\n",
      "Episode 1: reward: -250.000, steps: 200\n",
      "Episode 2: reward: -250.000, steps: 200\n",
      "Episode 3: reward: -250.000, steps: 200\n",
      "Episode 4: reward: -100.000, steps: 200\n",
      "Episode 5: reward: -250.000, steps: 200\n",
      "Episode 6: reward: -200.000, steps: 200\n",
      "Episode 7: reward: -250.000, steps: 200\n",
      "Episode 8: reward: -100.000, steps: 200\n",
      "Episode 9: reward: -250.000, steps: 200\n",
      "Episode 10: reward: -200.000, steps: 200\n",
      "Episode 11: reward: -250.000, steps: 200\n",
      "Episode 12: reward: -200.000, steps: 200\n",
      "Episode 13: reward: -200.000, steps: 200\n",
      "Episode 14: reward: -250.000, steps: 200\n",
      "Episode 15: reward: -200.000, steps: 200\n",
      "Episode 16: reward: -250.000, steps: 200\n",
      "Episode 17: reward: -250.000, steps: 200\n",
      "Episode 18: reward: -250.000, steps: 200\n",
      "Episode 19: reward: -250.000, steps: 200\n",
      "Episode 20: reward: -200.000, steps: 200\n",
      "Episode 21: reward: -250.000, steps: 200\n",
      "Episode 22: reward: -200.000, steps: 200\n",
      "Episode 23: reward: -250.000, steps: 200\n",
      "Episode 24: reward: -250.000, steps: 200\n",
      "Episode 25: reward: -100.000, steps: 200\n",
      "Episode 26: reward: -250.000, steps: 200\n",
      "Episode 27: reward: -250.000, steps: 200\n",
      "Episode 28: reward: -250.000, steps: 200\n",
      "Episode 29: reward: -200.000, steps: 200\n",
      "Episode 30: reward: 50.000, steps: 200\n",
      "Episode 31: reward: -100.000, steps: 200\n",
      "Episode 32: reward: -250.000, steps: 200\n",
      "Episode 33: reward: -250.000, steps: 200\n",
      "Episode 34: reward: -200.000, steps: 200\n",
      "Episode 35: reward: -250.000, steps: 200\n",
      "Episode 36: reward: -200.000, steps: 200\n",
      "Episode 37: reward: -250.000, steps: 200\n",
      "Episode 38: reward: -100.000, steps: 200\n",
      "Episode 39: reward: -250.000, steps: 200\n",
      "Episode 40: reward: -200.000, steps: 200\n",
      "Episode 41: reward: -200.000, steps: 200\n",
      "Episode 42: reward: -250.000, steps: 200\n",
      "Episode 43: reward: -250.000, steps: 200\n",
      "Episode 44: reward: -250.000, steps: 200\n",
      "Episode 45: reward: -200.000, steps: 200\n",
      "Episode 46: reward: -250.000, steps: 200\n",
      "Episode 47: reward: -250.000, steps: 200\n",
      "Episode 48: reward: -100.000, steps: 200\n",
      "Episode 49: reward: -250.000, steps: 200\n",
      "Episode 50: reward: -200.000, steps: 200\n",
      "Episode 51: reward: -250.000, steps: 200\n",
      "Episode 52: reward: -250.000, steps: 200\n",
      "Episode 53: reward: -250.000, steps: 200\n",
      "Episode 54: reward: -200.000, steps: 200\n",
      "Episode 55: reward: -250.000, steps: 200\n",
      "Episode 56: reward: -250.000, steps: 200\n",
      "Episode 57: reward: -250.000, steps: 200\n",
      "Episode 58: reward: -200.000, steps: 200\n",
      "Episode 59: reward: -100.000, steps: 200\n",
      "Episode 60: reward: -200.000, steps: 200\n",
      "Episode 61: reward: -200.000, steps: 200\n",
      "Episode 62: reward: -200.000, steps: 200\n",
      "Episode 63: reward: -200.000, steps: 200\n",
      "Episode 64: reward: -250.000, steps: 200\n",
      "Episode 65: reward: -250.000, steps: 200\n",
      "Episode 66: reward: -250.000, steps: 200\n",
      "Episode 67: reward: -250.000, steps: 200\n",
      "Episode 68: reward: -250.000, steps: 200\n",
      "Episode 69: reward: -250.000, steps: 200\n",
      "Episode 70: reward: 50.000, steps: 200\n",
      "Episode 71: reward: -200.000, steps: 200\n",
      "Episode 72: reward: -100.000, steps: 200\n",
      "Episode 73: reward: -250.000, steps: 200\n",
      "Episode 74: reward: -250.000, steps: 200\n",
      "Episode 75: reward: -250.000, steps: 200\n",
      "Episode 76: reward: -200.000, steps: 200\n",
      "Episode 77: reward: -250.000, steps: 200\n",
      "Episode 78: reward: -100.000, steps: 200\n",
      "Episode 79: reward: -100.000, steps: 200\n",
      "Episode 80: reward: -250.000, steps: 200\n",
      "Episode 81: reward: -200.000, steps: 200\n",
      "Episode 82: reward: -100.000, steps: 200\n",
      "Episode 83: reward: -200.000, steps: 200\n",
      "Episode 84: reward: -200.000, steps: 200\n",
      "Episode 85: reward: -250.000, steps: 200\n",
      "Episode 86: reward: -250.000, steps: 200\n",
      "Episode 87: reward: -200.000, steps: 200\n",
      "Episode 88: reward: -250.000, steps: 200\n",
      "Episode 89: reward: -200.000, steps: 200\n",
      "Episode 90: reward: -250.000, steps: 200\n",
      "Episode 91: reward: -200.000, steps: 200\n",
      "Episode 92: reward: -250.000, steps: 200\n",
      "Episode 93: reward: -200.000, steps: 200\n",
      "Episode 94: reward: -200.000, steps: 200\n",
      "Episode 95: reward: -250.000, steps: 200\n",
      "Episode 96: reward: -200.000, steps: 200\n",
      "Episode 97: reward: -250.000, steps: 200\n",
      "Episode 98: reward: -200.000, steps: 200\n",
      "Episode 99: reward: -200.000, steps: 200\n",
      "Episode 100: reward: -250.000, steps: 200\n",
      "-211.0\n"
     ]
    }
   ],
   "source": [
    "# running trained model for 100 times and getting average\n",
    "scores = dqn.test(env, nb_episodes = 100, visualize = False)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "dqn.save_weights('500k.h5f', overwrite = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
